# Previs√£o de Vendas no Varejo com Modelos de S√©rie Temporal

<a target="_blank" href="https://cookiecutter-data-science.drivendata.org/">
    <img src="https://img.shields.io/badge/CCDS-Project%20template-328F97?logo=cookiecutter" />
</a>

## üìå Vis√£o Geral

Este projeto implementa uma **solu√ß√£o end-to-end de previs√£o de vendas no varejo** utilizando abordagens modernas de s√©ries temporais. S√£o avaliados modelos como **Prophet**, **LSTM** e o **Temporal Fusion Transformer (TFT)**, dentro de um fluxo robusto e modularizado, pronto para ambientes de produ√ß√£o e pipelines MLOps.

O reposit√≥rio demonstra:
- **Automa√ß√£o** de todo ciclo: prepara√ß√£o de dados, treinamento, tuning, deploy, previs√£o e avalia√ß√£o;
- Uso intensivo de **PyTorch Lightning**, **MLflow** e **Optuna** (tracking, experimenta√ß√£o, automa√ß√£o de busca de hiperpar√¢metros);
- **Pipeline reproduz√≠vel** com Docker, Makefile, requirements e orquestra√ß√£o via scripts e notebooks;
- Organiza√ß√£o profissional seguindo padr√µes do Cookiecutter Data Science, pronto para integra√ß√£o em squads de dados.

---

## üìÇ Estrutura do Projeto

```
.
‚îú‚îÄ‚îÄ main/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py           # Inicializador de m√≥dulo Python
‚îÇ   ‚îú‚îÄ‚îÄ app.py                # (Exemplo: FastAPI - se usado)
‚îÇ   ‚îú‚îÄ‚îÄ conf.py               # Configura√ß√µes globais e paths
‚îÇ   ‚îú‚îÄ‚îÄ DataProcessor.py      # Classe de ETL, ingest√£o, splits, prepara√ß√£o, persist√™ncia
‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py         # Script CLI para avalia√ß√£o do modelo (test set, m√©tricas)
‚îÇ   ‚îú‚îÄ‚îÄ Model.py              # Defini√ß√£o da classe do modelo, treino, tuning, save/load
‚îÇ   ‚îú‚îÄ‚îÄ predict.py            # Script CLI para previs√£o usando modelo salvo
‚îÇ   ‚îú‚îÄ‚îÄ setup_db.py           # Setup de banco de dados e tabelas
‚îÇ   ‚îú‚îÄ‚îÄ train.py              # Script CLI para pipeline de treino/tuning/salvamento
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Makefile
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ final/                # Modelos finais (.ckpt)
‚îÇ   ‚îú‚îÄ‚îÄ study/                # Resultados de tuning (Optuna, etc)
‚îú‚îÄ‚îÄ logs/                     # Logs estruturados (loguru)
‚îú‚îÄ‚îÄ notebooks/                # An√°lises explorat√≥rias, valida√ß√£o manual, sanity check
‚îú‚îÄ‚îÄ data/                     # Estrutura de dados (raw, interim, processed)
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ LICENSE
```

---

## üöÄ Como Executar

### Requisitos

- **Docker** e **Docker Compose** (ambiente recomendado)
- Python 3.10+ (execu√ß√£o manual/local)

### 1. Clonando o Reposit√≥rio

```bash
git clone https://github.com/carloseduds/TS_Forecast_DL_TFT_dailySales.git
cd TS_Forecast_DL_TFT_dailySales
```

### 2. Subindo a Infraestrutura

#### Principais comandos do Makefile

- `make init`: Inicializa o ambiente, cria diret√≥rios necess√°rios, checa depend√™ncias e redes, **constr√≥i do zero** e sobe todos os containers (√∫til na primeira execu√ß√£o ou quando deseja garantir reprodutibilidade total).
- `make run`: Sobe os containers do projeto j√° existentes, sem for√ßar rebuild (√∫til para reativar rapidamente ap√≥s um shutdown).
- `make build`: Apenas constr√≥i as imagens Docker sem subir containers, √∫til para preparar builds customizados.
- `make clean`: Para e remove todos os containers e volumes associados ao projeto.
- `make destroy`: Remove containers, volumes e diret√≥rios de dados/notebooks/logs criados pelo projeto (aten√ß√£o: pode apagar dados locais).

```bash
make init     # Inicializa ambiente e sobe tudo do zero (build+up)
make run      # Sobe containers j√° existentes
make clean    # Remove containers e volumes
make destroy  # Limpa tudo (inclusive diret√≥rios do projeto)
```

### 3. Acessos e Credenciais

Ap√≥s subir a infraestrutura, acesse as principais interfaces do projeto:

- **Jupyter Notebook:** [http://localhost:8888](http://localhost:8888)  
  Senha: `secret`

- **MLflow UI:** [http://localhost:5000](http://localhost:5000)

- **MinIO Console:** [http://localhost:9001](http://localhost:9001)  
  Usu√°rio: `minio`  
  Senha: `minio123`


### 4. Pipeline de Modelagem (Exemplos de uso)

#### Treinar o Modelo e Otimizar os Hiperpar√¢metros

```bash
docker exec forecasting_jupyter python main/train.py --tune
```

#### Treinar o Modelo Final

```bash
docker exec forecasting_jupyter python main/train.py --train-best
```

#### Fazer Previs√£o

```bash
docker exec forecasting_jupyter python main/predict.py
```

#### Avaliar Modelo

```bash
docker exec forecasting_jupyter python main/evaluation.py
```

---

## üß© **Arquitetura do C√≥digo e Scripts**

| Arquivo                | Fun√ß√£o/Responsabilidade                                                                                                    |
|------------------------|---------------------------------------------------------------------------------------------------------------------------|
| `main/DataProcessor.py`| ETL, splits, processamento, persist√™ncia SQL/CSV, fun√ß√µes de transforma√ß√£o, gerenciamento de features e splits EDA        |
| `main/Model.py`        | Defini√ß√£o e controle do TFT, integra√ß√£o com MLflow/Optuna, treino, tuning, checkpointing, prediction, save/load           |
| `main/train.py`        | CLI para treino: tuning, treino final, logging, callbacks, integra√ß√£o robusta (utiliza DataProcessor e Model)             |
| `main/predict.py`      | CLI para gera√ß√£o de previs√µes com modelo treinado (ckpt)                                                                  |
| `main/evaluation.py`   | CLI para avalia√ß√£o automatizada: gera previs√µes, calcula m√©tricas e faz log no MLflow                                     |
| `main/conf.py`         | Centraliza paths, vari√°veis globais, setup de logging                                                                     |
| `main/setup_db.py`     | Inicializa√ß√£o e checagem do banco de dados Postgres                                                                       |

> **Diferenciais:**  
> - **Padroniza√ß√£o** dos scripts CLI para cada etapa;
> - **Separa l√≥gica de dados/modelo/execu√ß√£o** (facilita MLOps e integra√ß√£o em pipelines);
> - **Tracking** de experimentos, checkpoints e artefatos com MLflow;
> - **Logging estruturado** (loguru).

---

## üî¨ Tecnologias Utilizadas

- **PyTorch Lightning, Pytorch Forecasting:** Frameworks para deep learning e s√©ries temporais
- **MLflow:** Tracking de experimentos, tuning, artifacts
- **Optuna:** Otimiza√ß√£o autom√°tica de hiperpar√¢metros (com logging MLflow)
- **Docker:** Empacotamento, reprodutibilidade
- **SQLAlchemy + Postgres:** Persist√™ncia, ingest√£o, hist√≥rico de previs√µes
- **Loguru:** Logging moderno
- **Typer:** Scripts de linha de comando com UX profissional
- **JupyterLab:** Notebooks para explora√ß√£o manual

---

## üìö Recomenda√ß√µes e Extens√µes

- Pipeline pronto para integra√ß√£o com **CI/CD** (GitHub Actions, GitLab CI, etc)
- Pode ser plugado em infra de nuvem (AWS, Azure, GCP) ou servi√ßos gerenciados (MLflow Tracking Server)
- F√°cil adapta√ß√£o para outros dom√≠nios (previs√£o de demanda, risco, etc)
- Estrutura modular para incluir **testes unit√°rios** (`pytest`), alertas de drift, explainability (SHAP, etc)

---

## Autor

* **Autor:** Carlos Eduardo Correa
* **Base/Inspira√ß√£o para Infraestrutura:**
  * [Yong Liu](https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLFlow.git)
  * [Natu Lauchande](https://github.com/PacktPublishing/Machine-Learning-Engineering-with-Mlflow.git)
  * [cookiecutter-ds-docker](https://github.com/sertansenturk/cookiecutter-ds-docker)
  * Projetos-padr√£o de MLflow + Docker

---


## üìú Licen√ßa

MIT
