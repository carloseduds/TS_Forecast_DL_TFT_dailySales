{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72959558-3719-4790-85d1-e18dbc7c3246",
   "metadata": {},
   "source": [
    "# Escolha do Algoritmo de Validação Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e0358b",
   "metadata": {},
   "source": [
    "Neste notebook, selecionaremos o melhor método de validação cruzada para séries temporais, utilizando uma amostra do dataset do nosso projeto. Embora existam diversas estratégias de validação cruzada, neste estudo nos concentraremos em abordagens específicas para séries temporais, que respeitam a dependência temporal dos dados. Esse critério é essencial para dados de varejo, onde padrões sazonais e tendências ao longo do tempo influenciam significativamente as previsões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef0b2284-739f-43bb-8bad-186e941adcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89badc83-c7a3-4c0e-8b43-37025bd539f0",
   "metadata": {
    "collapsed": false,
    "executionCancelledAt": null,
    "executionTime": 880,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "lastExecutedAt": 1705680477369,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import pandas as pd\nimport numpy as np\nimport datetime\nfrom lightgbm import LGBMRegressor\n\n# Criar um conjunto de dados de séries temporais com feature e target\nnp.random.seed(42)\n\n# Criar um índice de datas\ndate_index = pd.date_range(start=\"2020-01-01\", periods=1000, freq=\"D\")\n\n# Gerar valores para a feature (tendência crescente)\nfeature_values = np.linspace(0, 10, num=1000) + np.random.randn(1000)\n\n# Gerar ruído aleatório para a target\nnoise = np.random.normal(0, 1, size=1000)\n\n# Calcular a target como uma função da feature e adicionar ruído\ntarget_values = 2 * feature_values + 5 + noise\n\n# Criar DataFrame de séries temporais com feature e target\ntime_series_data = pd.DataFrame({\"Feature\": feature_values, \"Target\": target_values}, index=date_index)\n\n# Exibir as primeiras linhas do DataFrame\nprint(time_series_data.head())\n\nX = time_series_data['Feature']\ny = time_series_data['Target']\n\n# Calcula os índices de divisão\nidx_split_test = int(len(X) * .70)\n\n# Divide os dados\nX_train_temp, X_test = X.iloc[:idx_split_test], X.iloc[idx_split_test:]\ny_train_temp, y_test = y.iloc[:idx_split_test], y.iloc[idx_split_test:]",
    "outputsMetadata": {
     "0": {
      "height": 143,
      "type": "stream"
     },
     "1": {
      "height": 320,
      "type": "dataFrame"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>in_training</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21708</th>\n",
       "      <td>TX_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>3950.35</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21709</th>\n",
       "      <td>TX_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>3844.97</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21710</th>\n",
       "      <td>TX_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>2888.03</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21711</th>\n",
       "      <td>TX_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>3631.28</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21712</th>\n",
       "      <td>TX_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>3072.18</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23644</th>\n",
       "      <td>TX_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>2016-05-18</td>\n",
       "      <td>5146.18</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23645</th>\n",
       "      <td>TX_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>2016-05-19</td>\n",
       "      <td>4647.91</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23646</th>\n",
       "      <td>TX_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>2016-05-20</td>\n",
       "      <td>5977.50</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23647</th>\n",
       "      <td>TX_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>2016-05-21</td>\n",
       "      <td>6776.10</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23648</th>\n",
       "      <td>TX_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>7770.28</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1941 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      store_id cat_id       date    sales  in_training\n",
       "21708     TX_1  FOODS 2011-01-29  3950.35         True\n",
       "21709     TX_1  FOODS 2011-01-30  3844.97         True\n",
       "21710     TX_1  FOODS 2011-01-31  2888.03         True\n",
       "21711     TX_1  FOODS 2011-02-01  3631.28         True\n",
       "21712     TX_1  FOODS 2011-02-02  3072.18         True\n",
       "...        ...    ...        ...      ...          ...\n",
       "23644     TX_1  FOODS 2016-05-18  5146.18         True\n",
       "23645     TX_1  FOODS 2016-05-19  4647.91         True\n",
       "23646     TX_1  FOODS 2016-05-20  5977.50         True\n",
       "23647     TX_1  FOODS 2016-05-21  6776.10         True\n",
       "23648     TX_1  FOODS 2016-05-22  7770.28         True\n",
       "\n",
       "[1941 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df_sales = pd.read_parquet(\"../data/processed/sales_cleaning_processed.parquet\")\n",
    "\n",
    "df_sales_filtrado = df_sales[(df_sales[\"store_id\"] == \"TX_1\") & (df_sales[\"cat_id\"] == \"FOODS\")]\n",
    "df_sales_filtrado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7b01ce-90e7-47c7-ba5b-68a8b263a6eb",
   "metadata": {},
   "source": [
    "# Prequential Expanding Split\n",
    "\n",
    "A estratégia de validação **Prequential Expanding Split** é uma abordagem baseada na divisão progressiva dos dados em **treino, validação e teste**, garantindo que o modelo seja avaliado de forma realista ao longo do tempo. Essa técnica é útil para cenários onde os dados evoluem continuamente, permitindo que o modelo se ajuste conforme novas informações se tornam disponíveis.\n",
    "\n",
    "## Como funciona a Validação Prequential Expanding?\n",
    "\n",
    "1. **Divisão dos Dados em Blocos**  \n",
    "   - O conjunto de dados é dividido em `n_block` partes sequenciais.  \n",
    "   - Cada bloco representa um período ou um segmento contínuo dos dados.\n",
    "\n",
    "2. **Definição dos Conjuntos**  \n",
    "   - Os primeiros blocos são usados para o treinamento do modelo.  \n",
    "   - O penúltimo bloco (`n_block - 2`) é reservado para a validação.  \n",
    "   - O último bloco (`n_block - 1`) é usado como teste.\n",
    "\n",
    "3. **Opção de Gap**  \n",
    "   - Se `gap=True`, há um espaço entre os conjuntos de treino e validação, garantindo que o modelo não treine diretamente nos dados mais próximos da validação e do teste.\n",
    "\n",
    "4. **Expansão Gradual**  \n",
    "   - Conforme mais dados se tornam disponíveis, o conjunto de treinamento cresce progressivamente.\n",
    "\n",
    "---\n",
    "\n",
    "## Vantagens da Abordagem Prequential Expanding\n",
    "\n",
    "- **Adaptação contínua**: permite que o modelo capture padrões que mudam ao longo do tempo.  \n",
    "- **Evita vazamento de dados**: a separação correta dos conjuntos previne a contaminação por informações futuras.  \n",
    "- **Reflete cenários reais de produção**: simula o fluxo contínuo de dados em sistemas dinâmicos.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ac75e60-6b5b-4abc-b969-c5ba0fdf16c3",
   "metadata": {
    "collapsed": false,
    "executionCancelledAt": null,
    "executionTime": 47384,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "lastExecutedAt": 1705681534225,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "def prequential_expanding_split(model, X, y, n_block, gap=False):\n    \"\"\"\n    Executa a validação prequential com divisão expansiva personalizada.\n\n    Parameters:\n    - model: Modelo de aprendizado de máquina\n    - X: DataFrame contendo as features\n    - y: DataFrame contendo os rótulos\n    - n_block: Número de blocos para dividir os dados\n    - gap: Flag indicando se deve ou não haver um intervalo (gap) entre os blocos\n\n    Returns:\n    - results_val: Lista com as métricas de desempenho para cada iteração.\n    \"\"\"\n    blocos_X = np.array_split(X.reset_index(), n_block)\n    blocos_y = np.array_split(y.reset_index(), n_block)\n\n    for i, (bloco_X, bloco_y) in enumerate(zip(blocos_X, blocos_y)):\n        bloco_X['block'] = i\n        bloco_y['block'] = i\n\n    novo_df_X = pd.concat(blocos_X, ignore_index=True).set_index('index')\n    novo_df_y = pd.concat(blocos_y, ignore_index=True).set_index('index')\n\n    results_val = []\n\n    start_block = 2 if gap else 1\n\n    for block in range(start_block, n_block):\n        if gap:\n            X_train = novo_df_X.loc[novo_df_X['block'] < block - 1].drop(columns='block')\n            y_train = novo_df_y.loc[novo_df_y['block'] < block - 1].drop(columns='block')\n        else:\n            X_train = novo_df_X.loc[novo_df_X['block'] < block].drop(columns='block')\n            y_train = novo_df_y.loc[novo_df_y['block'] < block].drop(columns='block')\n        \n        X_val = novo_df_X.loc[novo_df_X['block'] == block].drop(columns='block')\n        y_val = novo_df_y.loc[novo_df_y['block'] == block].drop(columns='block')\n\n        # Treinamento do modelo\n        model.fit(X_train.values, y_train.values)\n\n        # Realiza as previsões\n        predictions = pd.Series(model.predict(X_val.values.reshape(-1, 1)))\n        ranked_predictions = predictions.rank(pct=True, method=\"first\")\n\n        # Calcula a correlação entre os valores reais e as previsões\n        correlation = np.corrcoef(y_val.values.flatten(), ranked_predictions.values.flatten())[0, 1]\n        results_val.append(correlation)\n\n        if gap:\n            print(\"Train with gap blocks 0-{} - Validation Block {} - Correlation: {}\".format(block - 1, block, correlation))\n        else:\n            print(\"Train without gap blocks 0-{} - Validation Block {} - Correlation: {}\".format(block - 1, block, correlation))\n            \n    return results_val\n\n# Exemplo de uso\nvalores = prequential_expanding_split(mdl, X_train_temp, y_train_temp, 7, gap=False)\nnp.mean(valores)",
    "outputsMetadata": {
     "0": {
      "height": 269,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "def prequential_expanding_split(df, n_block, validation=True, gap=False):\n",
    "    \"\"\"\n",
    "    Implementa a divisão dos dados em treino, validação e teste seguindo o esquema prequential expanding window.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame contendo os dados, incluindo as features e a variável target.\n",
    "    - n_block: Número de blocos para dividir os dados.\n",
    "    - gap: Se True, adiciona um espaço entre treino e validação para evitar data leakage.\n",
    "\n",
    "    Returns:\n",
    "    - training_df: Dados de treino (janela crescente).\n",
    "    - validation_df: Dados de validação.\n",
    "    - test_df: Dados de teste.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    df = df.reset_index(drop=False)\n",
    "\n",
    "    # Criar 'series_id' se necessário\n",
    "    if \"series_id\" not in df.columns:\n",
    "        df = df.assign(series_id=df[\"store_id\"] + \"_\" + df[\"cat_id\"])\n",
    "\n",
    "    test_list, validation_list, training_list = [], [], []\n",
    "\n",
    "    # Iterar sobre cada série única\n",
    "    for series in df[\"series_id\"].unique():\n",
    "        df_series = df.loc[df[\"series_id\"] == series]\n",
    "        blocos = np.array_split(df_series.reset_index(), n_block)\n",
    "\n",
    "        for i, bloco in enumerate(blocos):\n",
    "            bloco[\"block\"] = i\n",
    "\n",
    "        novo_df = pd.concat(blocos, ignore_index=True).set_index(\"index\")\n",
    "\n",
    "        # Definição dos blocos de treino, validação e teste\n",
    "        test_block = n_block - 1 \n",
    "        val_block = n_block - 2\n",
    "        train_blocks = list(range(val_block - (1 if gap else 0)))\n",
    "\n",
    "        df_series_test = novo_df[novo_df[\"block\"] == test_block].drop(columns=\"block\")\n",
    "\n",
    "        if validation:\n",
    "            df_series_val = novo_df[novo_df[\"block\"] == val_block].drop(columns=\"block\")\n",
    "            df_series_train = novo_df[novo_df[\"block\"].isin(train_blocks)].drop(columns=\"block\")\n",
    "        else:\n",
    "            df_series_val = pd.DataFrame()\n",
    "            df_series_train = novo_df[novo_df[\"block\"].isin(train_blocks)].drop(columns=\"block\")\n",
    "\n",
    "        # Adicionar aos conjuntos\n",
    "        test_list.append(df_series_test)\n",
    "        validation_list.append(df_series_val)\n",
    "        training_list.append(df_series_train)\n",
    "\n",
    "    # Concatenar os DataFrames resultantes\n",
    "    return (\n",
    "        pd.concat(training_list, ignore_index=True),\n",
    "        pd.concat(validation_list, ignore_index=True) if validation else pd.DataFrame(),\n",
    "        pd.concat(test_list, ignore_index=True),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a39a64-1b4b-49e6-9028-d16f9f9d70cc",
   "metadata": {},
   "source": [
    "# Prequential Sliding Split\n",
    "\n",
    "O método de validação **Prequential Sliding Split** é uma técnica de **validação cruzada para fluxos de dados contínuos**, projetada para avaliar a performance de modelos que precisam se adaptar constantemente. Ao contrário da validação tradicional, onde o conjunto de treinamento cresce indefinidamente, nesta abordagem a janela de treino desliza ao longo do tempo, garantindo que o modelo esteja sempre treinando nos dados mais recentes.\n",
    "\n",
    "## Como funciona a Validação Prequential Sliding?\n",
    "\n",
    "1. **Divisão dos Dados em Blocos**  \n",
    "   - O conjunto de dados é segmentado em `n_block` partes sequenciais.  \n",
    "   - Cada bloco representa um período ou um conjunto contínuo de observações.\n",
    "\n",
    "2. **Janela Deslizante (Sliding Window)**  \n",
    "   - O modelo é treinado apenas com o bloco mais recente antes da validação.  \n",
    "   - Diferente da abordagem **Expanding**, onde o conjunto de treino cresce, aqui ele se move para frente, mantendo um tamanho fixo.\n",
    "\n",
    "3. **Avaliação Dinâmica**  \n",
    "   - A cada novo bloco, o modelo é treinado em um bloco e avaliado no próximo.  \n",
    "   - O penúltimo bloco (`n_block - 2`) é reservado para validação.  \n",
    "   - O último bloco (`n_block - 1`) é usado como teste final.\n",
    "\n",
    "4. **Adaptação a Mudanças nos Dados**  \n",
    "   - Como o conjunto de treinamento é sempre atualizado, o modelo se ajusta rapidamente a mudanças na distribuição dos dados, como variações sazonais e mudanças de regime.\n",
    "\n",
    "---\n",
    "\n",
    "## Vantagens da Validação Prequential Sliding\n",
    "\n",
    "- **Melhor para dados não estacionários**: útil para aplicações onde os padrões mudam rapidamente, como mercado financeiro e detecção de fraudes.  \n",
    "- **Evita o aprendizado de padrões obsoletos**: apenas os dados mais recentes são utilizados para treino.  \n",
    "- **Aplicável a cenários de streaming de dados**: ideal para aprendizado online e adaptação contínua.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f34b742-198c-48dc-883c-1b8d0a367c4d",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 19769,
    "lastExecutedAt": 1705681231938,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "def prequential_sliding_split(model, X, y, n_block, gap=False):\n    \"\"\"\n    Executa a validação prequential com divisão expansiva personalizada.\n\n    Parameters:\n    - model: Modelo de aprendizado de máquina\n    - X: DataFrame contendo as features\n    - y: DataFrame contendo os rótulos\n    - n_block: Número de blocos para dividir os dados\n    - gap: Flag indicando se deve ou não haver um intervalo (gap) entre os blocos\n\n    Returns:\n    - results_val: Lista com as métricas de desempenho para cada iteração.\n    \"\"\"\n    blocos_X = np.array_split(X.reset_index(), n_block)\n    blocos_y = np.array_split(y.reset_index(), n_block)\n\n    for i, (bloco_X, bloco_y) in enumerate(zip(blocos_X, blocos_y)):\n        bloco_X['block'] = i\n        bloco_y['block'] = i\n\n    novo_df_X = pd.concat(blocos_X, ignore_index=True).set_index('index')\n    novo_df_y = pd.concat(blocos_y, ignore_index=True).set_index('index')\n\n    results_val = []\n\n    start_block = 2 if gap else 1\n\n    for block in range(start_block, n_block):\n        X_train = novo_df_X.loc[novo_df_X['block'] == block - start_block].drop(columns='block')\n        y_train = novo_df_y.loc[novo_df_y['block'] == block - start_block].drop(columns='block')\n        \n        X_val = novo_df_X.loc[novo_df_X['block'] == block].drop(columns='block')\n        y_val = novo_df_y.loc[novo_df_y['block'] == block].drop(columns='block')\n\n        # Treinamento do modelo\n        model.fit(X_train.values, y_train.values)\n\n        # Realiza as previsões\n        predictions = pd.Series(model.predict(X_val.values.reshape(-1, 1)))\n        ranked_predictions = predictions.rank(pct=True, method=\"first\")\n\n        # Calcula a correlação entre os valores reais e as previsões\n        correlation = np.corrcoef(y_val.values.flatten(), ranked_predictions.values.flatten())[0, 1]\n        results_val.append(correlation)\n\n        if gap:\n            print(\"Train with gap blocks {} - Validation Block {} - Correlation: {}\".format(block - 2, block, correlation))\n        else:\n            print(\"Train without gap blocks {} - Validation Block {} - Correlation: {}\".format(block - 1, block, correlation))\n            \n    return results_val\n\n# Exemplo de uso\nvalores = prequential_sliding_split(mdl, X_train_temp, y_train_temp, 7, gap=False)\nnp.mean(valores)",
    "outputsMetadata": {
     "0": {
      "height": 269,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_sales = pd.read_parquet(\"../data/processed/sales_cleaning_processed.parquet\")\n",
    "\n",
    "def prequential_sliding_split(df, n_block, validation=True, gap=False):\n",
    "    \"\"\"\n",
    "    Implementa a divisão dos dados em treino, validação e teste seguindo o esquema prequential sliding window.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame contendo os dados, incluindo as features e a variável target.\n",
    "    - n_block: Número de blocos para dividir os dados.\n",
    "    - gap: Se True, adiciona um espaço entre treino e validação para evitar data leakage.\n",
    "\n",
    "    Returns:\n",
    "    - training_df: Dados de treino (apenas um bloco).\n",
    "    - validation_df: Dados de validação (próximo bloco após treino).\n",
    "    - test_df: Dados de teste (último bloco).\n",
    "    \"\"\"\n",
    "    # Criar uma cópia para evitar modificar o DataFrame original\n",
    "    df = df.copy()\n",
    "\n",
    "    df = df.reset_index(drop=False)\n",
    "\n",
    "    # Criar 'series_id' se necessário\n",
    "    if \"series_id\" not in df.columns:\n",
    "        df = df.assign(series_id=df[\"store_id\"] + \"_\" + df[\"cat_id\"])\n",
    "\n",
    "    test_list, validation_list, training_list = [], [], []\n",
    "\n",
    "    # Iterar sobre cada série única\n",
    "    for series in df[\"series_id\"].unique():\n",
    "        df_series = df.loc[df[\"series_id\"] == series]\n",
    "        blocos = np.array_split(df_series.reset_index(), n_block)\n",
    "\n",
    "        for i, bloco in enumerate(blocos):\n",
    "            bloco[\"block\"] = i\n",
    "\n",
    "        novo_df = pd.concat(blocos, ignore_index=True).set_index(\"index\")\n",
    "\n",
    "        # Definição dos blocos de treino, validação e teste\n",
    "        test_block = n_block - 1\n",
    "        val_block = n_block - 2\n",
    "        train_block = val_block - 1 if not gap else val_block - 2\n",
    "\n",
    "        df_series_test = novo_df[novo_df[\"block\"] == test_block].drop(columns=\"block\")\n",
    "\n",
    "        if validation:\n",
    "            df_series_val = novo_df[novo_df[\"block\"] == val_block].drop(columns=\"block\")\n",
    "            df_series_train = novo_df[novo_df[\"block\"] == train_block].drop(columns=\"block\")\n",
    "        else:\n",
    "            df_series_val = pd.DataFrame()\n",
    "            df_series_train = novo_df[novo_df[\"block\"] == train_block].drop(columns=\"block\")\n",
    "\n",
    "        # Adicionar aos conjuntos\n",
    "        test_list.append(df_series_test)\n",
    "        validation_list.append(df_series_val)\n",
    "        training_list.append(df_series_train)\n",
    "\n",
    "    # Concatenar os DataFrames resultantes\n",
    "    return (\n",
    "        pd.concat(training_list, ignore_index=True),\n",
    "        pd.concat(validation_list, ignore_index=True) if validation else pd.DataFrame(),\n",
    "        pd.concat(test_list, ignore_index=True),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc5e528",
   "metadata": {},
   "source": [
    "# Expanding Window Split\n",
    "\n",
    "O método de validação **Expanding Window Split** é uma técnica de **validação cruzada para séries temporais**, onde o tamanho do conjunto de treinamento cresce progressivamente a cada iteração. Essa abordagem é útil para modelagem preditiva em cenários onde novos dados se tornam disponíveis continuamente, permitindo que o modelo aprenda com um histórico cada vez maior.\n",
    "\n",
    "## Como funciona a Validação Expanding Window?\n",
    "\n",
    "1. **Divisão dos Dados em Blocos**  \n",
    "   - O conjunto de dados é segmentado em `n_block` partes sequenciais.  \n",
    "   - Cada bloco representa um período contínuo de observações.\n",
    "\n",
    "2. **Janela Expansiva (Expanding Window)**  \n",
    "   - O modelo é treinado em todos os blocos anteriores à validação.  \n",
    "   - A cada nova iteração, o conjunto de treinamento cresce, incorporando mais dados históricos.\n",
    "\n",
    "3. **Avaliação Dinâmica**  \n",
    "   - O penúltimo bloco (`n_block - 2`) é reservado para validação.  \n",
    "   - O último bloco (`n_block - 1`) é usado como teste final.\n",
    "\n",
    "4. **Adaptação a Mudanças nos Dados**  \n",
    "   - Como o conjunto de treinamento aumenta progressivamente, o modelo se ajusta melhor a tendências de longo prazo, capturando padrões históricos de forma mais robusta.\n",
    "\n",
    "---\n",
    "\n",
    "## Vantagens da Validação Expanding Window\n",
    "\n",
    "- **Aprendizado progressivo**: permite que o modelo utilize um histórico crescente de dados, melhorando a estabilidade das previsões.  \n",
    "- **Ideal para séries temporais**: mantém a ordem cronológica dos dados, essencial para previsões realistas.  \n",
    "- **Reflete aplicações do mundo real**: útil para modelos que devem considerar tendências de longo prazo.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5efe05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expanding_window_split(df, split_num, prediction_length=28, validation=True):\n",
    "    \"\"\"\n",
    "    Implementa a divisão dos dados em treino, validação e teste seguindo uma estratégia de cross-validation.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame contendo as séries temporais, incluindo as colunas 'store_id', 'cat_id' e 'date'.\n",
    "    - split_num: Número do split para controle do deslocamento das janelas de treino e teste.\n",
    "    - prediction_length: Número de dias para cada janela de previsão.\n",
    "    - validation: Booleano indicando se deve incluir um conjunto de validação.\n",
    "\n",
    "    Returns:\n",
    "    - training_df: DataFrame com os dados de treino.\n",
    "    - validation_df: DataFrame com os dados de validação (se `validation=True`).\n",
    "    - test_df: DataFrame com os dados de teste.\n",
    "    \"\"\"\n",
    "\n",
    "    # Criar uma cópia para evitar modificar o DataFrame original\n",
    "    df = df.copy()\n",
    "\n",
    "    df = df.reset_index(drop=False)\n",
    "\n",
    "    # Criar 'series_id' se necessário\n",
    "    if \"series_id\" not in df.columns:\n",
    "        df = df.assign(series_id=df[\"store_id\"] + \"_\" + df[\"cat_id\"])\n",
    "\n",
    "    test_list, validation_list, training_list = [], [], []\n",
    "\n",
    "    # Calcular deslocamentos de datas baseados em `split_num`\n",
    "    test_offset = prediction_length * ((split_num + 1) * 2 - 1)\n",
    "    val_offset = prediction_length * (split_num + 1) * 2\n",
    "    test_upper_offset = prediction_length * (split_num * 2)\n",
    "\n",
    "    # Iterar sobre cada série única\n",
    "    for series in df[\"series_id\"].unique():\n",
    "        df_series = df.loc[df[\"series_id\"] == series]\n",
    "        max_date = df_series[\"date\"].max()\n",
    "        min_date = df_series[\"date\"].min()\n",
    "\n",
    "        # Calcular limites de datas para cada conjunto\n",
    "        test_lower_date = max_date - pd.Timedelta(f\"{test_offset} days\")\n",
    "        test_upper_date = max_date - pd.Timedelta(f\"{test_upper_offset} days\")\n",
    "        val_lower_date = max_date - pd.Timedelta(f\"{val_offset} days\")\n",
    "\n",
    "        # Verificar se há dados suficientes para a divisão\n",
    "        if min(test_lower_date, test_upper_date) < min_date:\n",
    "            raise ValueError(\n",
    "                f\"A série '{series}' não possui dados suficientes para o split {split_num}. \"\n",
    "                f\"Data mínima: {min_date}, necessário: {test_lower_date}.\"\n",
    "            )\n",
    "\n",
    "        # Aplicar filtros para separar os conjuntos de dados\n",
    "        df_series_test = df_series.query(\"date > @test_lower_date and date <= @test_upper_date\")\n",
    "        df_series_val = (\n",
    "            df_series.query(\"date > @val_lower_date and date <= @test_lower_date\")\n",
    "            if validation\n",
    "            else pd.DataFrame()\n",
    "        )\n",
    "        df_series_train = (\n",
    "            df_series.query(\"date <= @val_lower_date\")\n",
    "            if validation\n",
    "            else df_series.query(\"date <= @test_lower_date\")\n",
    "        )\n",
    "\n",
    "        # Adicionar aos conjuntos\n",
    "        test_list.append(df_series_test)\n",
    "        validation_list.append(df_series_val)\n",
    "        training_list.append(df_series_train)\n",
    "\n",
    "    # Concatenar os DataFrames resultantes\n",
    "    return (\n",
    "        pd.concat(training_list, ignore_index=True),\n",
    "        pd.concat(validation_list, ignore_index=True) if validation else pd.DataFrame(),\n",
    "        pd.concat(test_list, ignore_index=True),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b168ea",
   "metadata": {},
   "source": [
    "Para nosso projeto, realizaremos um teste para garantir que a escolha da estratégia de cross-validation seja baseada no melhor resultado e em sua aplicabilidade prática. Para isso, criaremos um modelo simples de previsão de vendas e avaliaremos o desempenho de cada uma das abordagens de validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4581ea76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Método de Split: prequential_expanding\n",
      " - Métricas Validação: {'MAE': 748.7203346256707, 'MSE': 931445.955538253, 'RMSE': np.float64(965.1144779445872), 'MAPE': np.float64(15.304957661140847)}\n",
      " - Métricas Teste:     {'MAE': 750.6894226595261, 'MSE': 880171.306406956, 'RMSE': np.float64(938.1744541432345), 'MAPE': np.float64(14.494219661012586)}\n",
      "\n",
      "Método de Split: prequential_sliding\n",
      " - Métricas Validação: {'MAE': 748.7203346256707, 'MSE': 931445.955538253, 'RMSE': np.float64(965.1144779445872), 'MAPE': np.float64(15.304957661140847)}\n",
      " - Métricas Teste:     {'MAE': 750.6894226595261, 'MSE': 880171.306406956, 'RMSE': np.float64(938.1744541432345), 'MAPE': np.float64(14.494219661012586)}\n",
      "\n",
      "Método de Split: expanding_window\n",
      " - Métricas Validação: {'MAE': 676.6035249467376, 'MSE': 611017.3399737701, 'RMSE': np.float64(781.6759814486883), 'MAPE': np.float64(15.077434220983314)}\n",
      " - Métricas Teste:     {'MAE': 798.6517968854467, 'MSE': 806503.9658264604, 'RMSE': np.float64(898.0556585348485), 'MAPE': np.float64(18.05702131313266)}\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "# Função para calcular as métricas de avaliação\n",
    "def avaliar_metricas(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    # Evita divisão por zero ao calcular o MAPE\n",
    "    y_true_nonzero = y_true[y_true != 0]\n",
    "    y_pred_nonzero = y_pred[y_true != 0]\n",
    "    if len(y_true_nonzero) > 0:\n",
    "        mape = np.mean(np.abs((y_true_nonzero - y_pred_nonzero) / y_true_nonzero)) * 100\n",
    "    else:\n",
    "        mape = np.nan\n",
    "    return {\"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"MAPE\": mape}\n",
    "\n",
    "\n",
    "# Função para previsão com ARIMA\n",
    "def arima_forecast(train, steps, order=(1, 1, 1)):\n",
    "    \"\"\"\n",
    "    Ajusta um modelo ARIMA na série de treino e prevê os próximos 'steps' períodos.\n",
    "    \"\"\"\n",
    "    # Ordena os dados pela coluna 'date'\n",
    "    train = train.sort_values(\"date\")\n",
    "    modelo = ARIMA(train[\"sales\"], order=order)\n",
    "    modelo_fit = modelo.fit()\n",
    "    previsao = modelo_fit.forecast(steps=steps)\n",
    "    return previsao.values\n",
    "\n",
    "\n",
    "# Função auxiliar para aplicar o split, ajustar ARIMA e avaliar as métricas\n",
    "def avaliar_split_arima(split_func, df, forecast_order=(1, 1, 1), **kwargs):\n",
    "    # Realiza a divisão dos dados\n",
    "    train_df, val_df, test_df = split_func(df, **kwargs)\n",
    "\n",
    "    if len(train_df) == 0:\n",
    "        raise ValueError(\"Não há dados suficientes no conjunto de treino.\")\n",
    "\n",
    "    # Previsão e avaliação para o conjunto de validação (se existir)\n",
    "    if not val_df.empty:\n",
    "        y_val_true = val_df[\"sales\"].values\n",
    "        try:\n",
    "            y_val_pred = arima_forecast(train_df, len(val_df), order=forecast_order)\n",
    "        except Exception as e:\n",
    "            print(\"Erro ao ajustar ARIMA na validação:\", e)\n",
    "            y_val_pred = np.full(len(val_df), np.nan)\n",
    "        val_metrics = avaliar_metricas(y_val_true, y_val_pred)\n",
    "    else:\n",
    "        val_metrics = {\"MAE\": np.nan, \"MSE\": np.nan, \"RMSE\": np.nan, \"MAPE\": np.nan}\n",
    "\n",
    "    # Re-treina o modelo usando treino + validação para previsão no teste\n",
    "    full_train_val = pd.concat([train_df, val_df], ignore_index=True).sort_values(\"date\")\n",
    "    if len(full_train_val) == 0:\n",
    "        raise ValueError(\"Não há dados suficientes para re-treino.\")\n",
    "    y_test_true = test_df[\"sales\"].values\n",
    "    try:\n",
    "        y_test_pred = arima_forecast(full_train_val, len(test_df), order=forecast_order)\n",
    "    except Exception as e:\n",
    "        print(\"Erro ao ajustar ARIMA no teste:\", e)\n",
    "        y_test_pred = np.full(len(test_df), np.nan)\n",
    "    test_metrics = avaliar_metricas(y_test_true, y_test_pred)\n",
    "\n",
    "    return {\"val_metrics\": val_metrics, \"test_metrics\": test_metrics}\n",
    "\n",
    "\n",
    "# Supondo que o DataFrame 'df_sales_filtrado' já esteja carregado e filtrado:\n",
    "df = df_sales_filtrado.copy()\n",
    "\n",
    "resultados_arima = {}\n",
    "\n",
    "# 1) Prequential Expanding Split com ARIMA\n",
    "resultados_arima[\"prequential_expanding\"] = avaliar_split_arima(\n",
    "    split_func=prequential_expanding_split,\n",
    "    df=df,\n",
    "    n_block=3,\n",
    "    validation=True,\n",
    "    gap=False,\n",
    "    forecast_order=(1, 1, 1),\n",
    ")\n",
    "\n",
    "# 2) Prequential Sliding Split com ARIMA\n",
    "resultados_arima[\"prequential_sliding\"] = avaliar_split_arima(\n",
    "    split_func=prequential_sliding_split,\n",
    "    df=df,\n",
    "    n_block=3,\n",
    "    validation=True,\n",
    "    gap=False,\n",
    "    forecast_order=(1, 1, 1),\n",
    ")\n",
    "\n",
    "# 3) Expanding Window Split com ARIMA\n",
    "resultados_arima[\"expanding_window\"] = avaliar_split_arima(\n",
    "    split_func=expanding_window_split,\n",
    "    df=df,\n",
    "    split_num=3,\n",
    "    prediction_length=28,\n",
    "    validation=True,\n",
    "    forecast_order=(1, 1, 1),\n",
    ")\n",
    "\n",
    "# Exibindo os resultados de forma organizada\n",
    "for metodo, valores in resultados_arima.items():\n",
    "    print(f\"\\nMétodo de Split: {metodo}\")\n",
    "    print(\" - Métricas Validação:\", valores[\"val_metrics\"])\n",
    "    print(\" - Métricas Teste:    \", valores[\"test_metrics\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3164a3ab",
   "metadata": {},
   "source": [
    "## Comparação de Desempenho das Estratégias de Split\n",
    "\n",
    "| Método de Split            | Conjunto    | **MAE ↓**     | **MSE ↓**        | **RMSE ↓**    | **MAPE ↓**   |\n",
    "|----------------------------|------------|--------------|----------------|--------------|-------------|\n",
    "| **Prequential Expanding**  | Validação  | **748.72**   | **931,445.96** | **965.11**   | **15.30%**  |\n",
    "|                            | Teste      | **750.69**   | **880,171.31** | **938.17**   | **14.49%**  |\n",
    "| **Prequential Sliding**    | Validação  | **748.72**   | **931,445.96** | **965.11**   | **15.30%**  |\n",
    "|                            | Teste      | **750.69**   | **880,171.31** | **938.17**   | **14.49%**  |\n",
    "| **Expanding Window**       | Validação  | **676.60** ✅ | **611,017.34** ✅ | **781.67** ✅ | **15.08%** ✅ |\n",
    "|                            | Teste      | **798.65** ❌ | **806,503.97** ✅ | **898.06** ✅ | **18.06%** ❌ |\n",
    "\n",
    "✅ **Melhores valores em cada métrica estão destacados.**  \n",
    "❌ **Piores valores em cada métrica estão indicados.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a783ccff",
   "metadata": {},
   "source": [
    "# Comparação das Estratégias de Validação Cruzada para Séries Temporais\n",
    "\n",
    "A tabela abaixo compara as três abordagens de **validação cruzada para séries temporais**, considerando diferentes critérios de aplicação e refletindo os resultados obtidos na nova base de dados:\n",
    "\n",
    "| Critério                                            | Expanding Window Split               | Prequential Sliding Split             | Prequential Expanding Split             |\n",
    "|-----------------------------------------------------|--------------------------------------|---------------------------------------|-----------------------------------------|\n",
    "| **Séries temporais reais**                          | ✅ Bom para séries estáveis          | ⚠️ Pode ser arriscado se houver mudanças abruptas  | ✅ Excelente para capturar tendências e sazonalidades  |\n",
    "| **Aprendizado incremental**                         | ⚠️ O modelo re-treina com todo o histórico, o que pode ser ineficiente | ✅ Indicado para cenários de streaming | ✅ Permite aprendizado incremental com um histórico crescente  |\n",
    "| **Dados de varejo (sazonais ou promocionais)**      | ⚠️ Pode demandar ajustes finos       | ⚠️ Pode não capturar todo o histórico | ✅ Adapta-se melhor a padrões sazonais e promoções  |\n",
    "| **Garantia de causalidade**                         | ✅ Sim                              | ⚠️ Se a janela de treino incluir dados do futuro, pode haver vazamento | ✅ Sim                                 |\n",
    "| **Volume grande de dados**                          | ⚠️ Pode ser mais lento               | ✅ Mais eficiente                     | ⚠️ Pode ser mais custoso computacionalmente  |\n",
    "| **Previsão futura realista**                        | ✅ Sim                              | ❌ Pode deixar de capturar o contexto completo | ✅ Sim                                 |\n",
    "\n",
    "---\n",
    "\n",
    "## Explicação dos Métodos com Base nos Resultados Obtidos\n",
    "\n",
    "### **Expanding Window Split**\n",
    "Essa abordagem utiliza um conjunto de treino que cresce progressivamente a cada novo split. Nos resultados apresentados, observamos que o método apresentou **MAE** de **676.60** e **RMSE** de **781.68** na **validação**, e **MAE** de **798.65** e **RMSE** de **898.06** no **teste**.\n",
    "\n",
    "Embora essa abordagem funcione bem para **séries temporais estáveis**, pode demandar **ajustes finos** para lidar com padrões de varejo, onde há sazonalidades e promoções frequentes. Além disso, como o modelo sempre re-treina com todo o histórico, esse método pode se tornar **mais custoso em termos computacionais**, especialmente com grandes volumes de dados. No entanto, o **Expanding Window garantiu o menor erro na validação**, demonstrando maior estabilidade preditiva.\n",
    "\n",
    "### **Prequential Sliding Split**\n",
    "A estratégia de _sliding window_ utiliza uma janela fixa para treino e validação, sendo vantajosa para **aprendizado incremental**, como fluxos contínuos de dados. No entanto, se a janela de treino não for bem definida, pode haver risco de **vazamento de informações do futuro**, violando a causalidade.\n",
    "\n",
    "Nos testes realizados, os erros foram **MAE ≈ 748.72** e **RMSE ≈ 965.11** na **validação**, e **MAE ≈ 750.69** e **RMSE ≈ 938.17** no **teste**. Apesar disso, essa abordagem pode ser arriscada para séries com mudanças graduais e padrões sazonais bem definidos. Em cenários onde há variações súbitas, essa estratégia pode não ser a melhor escolha, pois pode ignorar padrões sazonais antigos que ainda influenciam a previsão.\n",
    "\n",
    "### **Prequential Expanding Split**\n",
    "Essa abordagem combina a vantagem do **crescimento progressivo do histórico** com a capacidade de adaptação a mudanças graduais e padrões sazonais. Isso se torna particularmente relevante para **dados de varejo**, onde ciclos de promoção e sazonalidade afetam diretamente a previsão.\n",
    "\n",
    "Os resultados indicam um desempenho muito próximo ao _sliding_, com **MAE ≈ 748.72** e **RMSE ≈ 965.11** na **validação**, e **MAE ≈ 750.69** e **RMSE ≈ 938.17** no **teste**. No entanto, o _prequential expanding_ tem a vantagem adicional de **preservar a ordem temporal** e proporcionar uma previsão **mais realista do futuro**. Como o modelo aprende de forma incremental com um **histórico crescente**, essa abordagem **é ideal para capturar tendências e padrões sazonais sem perder informações passadas**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Conclusão e Escolha Final**\n",
    "**Dado o desempenho mais consistente e menor erro na validação, o Expanding Window foi escolhido como a melhor estratégia de validação cruzada.**  \n",
    "\n",
    "Embora possa ser **mais custoso computacionalmente**, ele **garante menor erro médio e maior estabilidade preditiva**, sendo **a melhor opção para previsões futuras em séries temporais estáveis**. Em um ambiente de varejo, ajustes finos podem ser necessários, mas a vantagem de **preservar padrões históricos e garantir causalidade** faz dessa a abordagem mais confiável.\n",
    "\n",
    "**Essa escolha, vai garantir um modelo mais robusto e estável para previsão em séries temporais!**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
