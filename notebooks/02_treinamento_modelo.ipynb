{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from prophet import Prophet\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pytorch_forecasting import TimeSeriesDataSet, RecurrentNetwork\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.models import TemporalFusionTransformer\n",
    "from pytorch_forecasting.metrics import MAE, MAPE\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "\n",
    "\n",
    "from src.treinamento_modelo import (\n",
    "    expanding_window_split,\n",
    "    plotar_previsao,\n",
    "    previsao_naive,\n",
    "    previsao_snaive,\n",
    "    calcular_wmae_wmape,\n",
    "    previsao_prophet,\n",
    "    modelagem_lstm,\n",
    "    previsao_lstm,\n",
    "    previsao_tft\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "#%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os dados processados\n",
    "df_sales_processed = pd.read_parquet(\"../data/processed/sales_cleaning_processed.parquet\")\n",
    "\n",
    "df_sales_processed.set_index(\"date\", inplace=True)\n",
    "df_sales_processed[\"series_id\"] = (\n",
    "    df_sales_processed[\"store_id\"] + \"_\" + df_sales_processed[\"cat_id\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           store_id cat_id    sales  in_training\n",
      "date                                            \n",
      "2011-01-29     CA_1  FOODS  7240.65         True\n",
      "2011-01-30     CA_1  FOODS  6705.51         True\n",
      "2011-01-31     CA_1  FOODS  4584.85         True\n",
      "2011-02-01     CA_1  FOODS  4965.46         True\n",
      "2011-02-02     CA_1  FOODS  4368.07         True\n"
     ]
    }
   ],
   "source": [
    "# Verificando os dados\n",
    "print(df_sales_processed.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir deste ponto, criaremos os modelos para a previs√£o no varejo. Inicialmente, construiremos um modelo base simples que servir√° como benchmark para compara√ß√£o com modelos mais complexos.\n",
    "\n",
    "Como ainda n√£o sabemos qual algoritmo ser√° mais adequado para os nossos dados, adotaremos uma abordagem explorat√≥ria. Primeiramente, testaremos diversos modelos de machine learning e deep learning utilizando seus hiperpar√¢metros padr√£o, a menos que ajustes sejam estritamente necess√°rios.\n",
    "\n",
    "Ap√≥s essa an√°lise preliminar de desempenho, selecionaremos o modelo mais promissor e, ent√£o, aplicaremos t√©cnicas de otimiza√ß√£o para aprimor√°-lo. Dessa forma, criaremos dois modelos: um baseline, que servir√° como refer√™ncia, e outro refinado, ajustado a partir dos insights obtidos na primeira etapa de experimenta√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M√©todo Naive para a primeira divis√£o de CV\n",
    "training_df, _, test_df = expanding_window_split(df_sales_processed, 0, validation=False)\n",
    "naive_test_df = previsao_naive(training_df, test_df)\n",
    "naive_test_df.info()\n",
    "naive_test_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos plotar as previs√µes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando a previs√£o\n",
    "plotar_previsao(naive_test_df, \"TX_2_FOODS\", \"naive_pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do nosso gr√°fico, podemos observar que as previs√µes do m√©todo **Na√Øve** s√£o pouco informativas, pois resultam em uma linha horizontal constante. Isso era esperado, j√° que se trata de um modelo ing√™nuo.\n",
    "\n",
    "Agora, vamos implementar o m√©todo **sNa√Øve**. Diferente do m√©todo **Na√Øve**, que simplesmente utiliza o √∫ltimo valor observado como previs√£o para todos os per√≠odos futuros, o m√©todo **sNa√Øve** leva em conta a sazonalidade dos dados. No nosso caso, a previs√£o para um determinado dia ser√° baseada no valor observado no mesmo dia da semana anterior, considerando um per√≠odo sazonal de **7 dias**, conforme identificado na fase de explora√ß√£o dos dados. Isso permite que o modelo capture padr√µes recorrentes dentro da s√©rie temporal, tornando-o um baseline mais robusto para s√©ries com comportamento sazonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previs√µes sNaive para a primeira divis√£o de CV\n",
    "training_df, _, test_df = expanding_window_split(df_sales_processed, 0, validation=False)\n",
    "snaive_test_df = previsao_snaive(training_df, test_df)\n",
    "snaive_test_df.info()\n",
    "snaive_test_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da mesma forma, vamos plotar as previs√µes do m√©todo **sNa√Øve** em compara√ß√£o com as vendas reais para uma s√©rie temporal aleat√≥ria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotar_previsao(snaive_test_df, \"TX_2_FOODS\", \"snaive_pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desta vez, as previs√µes do m√©todo **sNa√Øve** parecem muito mais realistas, conseguindo, de certa forma, acompanhar as oscila√ß√µes das vendas reais.  \n",
    "\n",
    "Sabemos, de forma intuitiva, que o m√©todo **sNa√Øve** √© um baseline mais adequado do que o **Na√Øve**, pois consegue capturar padr√µes sazonais nos dados. No entanto, para avaliar seu desempenho de forma objetiva, podemos utilizar m√©tricas como **MAE (Mean Absolute Error)** e **MAPE (Mean Absolute Percentage Error)**, que nos ajudam a quantificar a precis√£o das previs√µes.  \n",
    "\n",
    "De acordo com o Prof. **Rob Hyndman**, em seu [artigo](https://robjhyndman.com/papers/foresight.pdf), existem quatro tipos principais de m√©tricas para avalia√ß√£o de previs√µes em s√©ries temporais. No nosso caso, utilizaremos **MAE** e **MAPE** para cada s√©rie individualmente.  \n",
    "\n",
    "Al√©m disso, como estamos lidando com m√∫ltiplas s√©ries temporais, precisamos calcular um escore geral ponderado que combine todas elas. Para isso, seguimos a abordagem adotada na [Competi√ß√£o M5 do Kaggle](https://www.kaggle.com/c/m5-forecasting-accuracy/overview/evaluation), onde o peso de cada s√©rie √© baseado no total de vendas em d√≥lares das √∫ltimas **28 observa√ß√µes** do conjunto de treinamento. Essa pondera√ß√£o garante que s√©ries com maior impacto nas vendas tenham maior influ√™ncia na m√©trica final, proporcionando uma avalia√ß√£o mais representativa da performance do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de m√©todos de previs√£o e seus respectivos nomes de coluna no DataFrame\n",
    "metodos_previsao = [(previsao_naive, \"naive_pred\"), (previsao_snaive, \"snaive_pred\")]\n",
    "\n",
    "cv = 3\n",
    "resultados_naive = []\n",
    "\n",
    "for metodo, nome_previsto in metodos_previsao:\n",
    "    wmae_lista = []\n",
    "    wmape_lista = []\n",
    "\n",
    "    for i in range(cv):\n",
    "        training_df, _, test_df = expanding_window_split(df_sales_processed, i, validation=False)\n",
    "        test_df_previsto = metodo(training_df, test_df)  # Aplica o m√©todo de previs√£o\n",
    "        wmae, wmape = calcular_wmae_wmape(training_df, test_df_previsto, \"sales\", nome_previsto)\n",
    "\n",
    "        wmae_lista.append(wmae)\n",
    "        wmape_lista.append(wmape)\n",
    "\n",
    "    # Armazena os resultados em uma lista\n",
    "    resultados_naive.append(\n",
    "        {\n",
    "            \"Modelo\": nome_previsto,\n",
    "            \"WMAE - M√©dia CV\": np.mean(wmae_lista),\n",
    "            \"WMAE - Desvio Padr√£o CV\": np.std(wmae_lista),\n",
    "            \"WMAPE - M√©dia CV\": np.mean(wmape_lista),\n",
    "            \"WMAPE - Desvio Padr√£o CV\": np.std(wmape_lista),\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Criando DataFrame com os resultados de ambos os m√©todos\n",
    "df_resultados_naive = pd.DataFrame(resultados_naive)\n",
    "\n",
    "# Exibir os resultados formatados\n",
    "df_resultados_naive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base no WMAE (Erro Absoluto M√©dio Ponderado) calculado a partir da valida√ß√£o cruzada em tr√™s divis√µes, o m√©todo sNa√Øve apresenta um erro quase 50% menor em compara√ß√£o com o m√©todo Na√Øve.\n",
    "\n",
    "Da mesma forma, ao analisar o WMAPE (Erro Percentual Absoluto M√©dio Ponderado), observamos que o modelo sNa√Øve tamb√©m supera o Na√Øve, confirmando sua melhor capacidade de capturar padr√µes sazonais nos dados.\n",
    "\n",
    "Diante desses resultados, adotaremos o sNa√Øve como nosso baseline para as previs√µes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Prophet √© um modelo desenvolvido pelo Facebook, especialmente projetado para a previs√£o de s√©ries temporais com sazonalidades, tend√™ncias e eventos especiais. Ele se destaca por sua facilidade de uso, capacidade de capturar padr√µes complexos e robustez na presen√ßa de dados irregulares ou lacunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar modelo Prophet para a primeira divis√£o de CV\n",
    "cv = 0\n",
    "training_df, validation_df, test_df = expanding_window_split(df_sales_processed, cv, validation=True)\n",
    "prophet_test_df = previsao_prophet(training_df, validation_df, cv)\n",
    "prophet_test_df.info()\n",
    "prophet_test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Prophet predictions against actual sales\n",
    "plotar_previsao(prophet_test_df, \"TX_1_FOODS\", \"prophet_pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de m√©todos de previs√£o e seus respectivos nomes de coluna no DataFrame\n",
    "metodos_previsao = [(previsao_prophet, \"prophet_pred\")]\n",
    "\n",
    "cv = 3\n",
    "resultados_prophet = []\n",
    "\n",
    "for metodo, nome_previsto in metodos_previsao:\n",
    "    wmae_lista = []\n",
    "    wmape_lista = []\n",
    "\n",
    "    for i in range(cv):\n",
    "        training_df, _, test_df = expanding_window_split(df_sales_processed, i, validation=False)\n",
    "        test_df_previsto = metodo(training_df, test_df, 0)\n",
    "        wmae, wmape = calcular_wmae_wmape(training_df, test_df_previsto, \"sales\", nome_previsto)\n",
    "\n",
    "        wmae_lista.append(wmae)\n",
    "        wmape_lista.append(wmape)\n",
    "\n",
    "    # Armazena os resultados em uma lista\n",
    "    resultados_prophet.append(\n",
    "        {\n",
    "            \"Modelo\": nome_previsto,\n",
    "            \"WMAE - M√©dia CV\": np.mean(wmae_lista),\n",
    "            \"WMAE - Desvio Padr√£o CV\": np.std(wmae_lista),\n",
    "            \"WMAPE - M√©dia CV\": np.mean(wmape_lista),\n",
    "            \"WMAPE - Desvio Padr√£o CV\": np.std(wmape_lista),\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Criando DataFrame com os resultados de ambos os m√©todos\n",
    "df_resultados_prophet = pd.DataFrame(resultados_prophet)\n",
    "\n",
    "# Exibir os resultados formatados\n",
    "df_resultados_geral = pd.concat([df_resultados_naive, df_resultados_prophet])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que o **Prophet** apresentou um desempenho superior aos m√©todos de previs√£o **Na√Øve** e **sNa√Øve**. Esse resultado pode ser atribu√≠do √† sua capacidade de capturar tanto **sazonalidades** quanto **tend√™ncias** presentes nos dados, resultando em erros significativamente menores.  \n",
    "\n",
    "Al√©m disso, o **Prophet** √© um modelo robusto e de f√°cil implementa√ß√£o, o que o torna uma excelente op√ß√£o para previs√µes de s√©ries temporais, especialmente quando h√° padr√µes complexos que os m√©todos ing√™nuos n√£o conseguem captar adequadamente.  \n",
    "\n",
    "At√© o momento, esse modelo seria a melhor op√ß√£o para realizarmos o **ajuste fino**, visando otimizar ainda mais as previs√µes. No entanto, tamb√©m consideramos testar um modelo de **deep learning** para avaliar se conseguimos obter um desempenho ainda melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo **LSTM (Long Short-Term Memory)** √© um tipo de rede neural recorrente (RNN) projetado para lidar com **dados sequenciais**, sendo amplamente utilizado em **s√©ries temporais** devido √† sua capacidade de capturar depend√™ncias de longo prazo. Diferente das RNNs tradicionais, o **LSTM** resolve o problema do **desvanecimento do gradiente**, permitindo que o modelo retenha informa√ß√µes relevantes ao longo do tempo.  \n",
    "\n",
    "No contexto de s√©ries temporais, o **LSTM** √© capaz de identificar **padr√µes n√£o lineares, tend√™ncias e sazonalidades**, tornando-se uma abordagem poderosa para previs√µes. Ele pode ser aplicado em diversas √°reas, como previs√£o de demanda, detec√ß√£o de anomalias e modelagem financeira, oferecendo uma alternativa robusta aos m√©todos estat√≠sticos tradicionais.  \n",
    "\n",
    "Neste projeto, exploramos o **LSTM** como uma solu√ß√£o avan√ßada para melhorar a precis√£o das previs√µes, aproveitando sua capacidade de aprender padr√µes complexos nos dados e adaptar-se a varia√ß√µes din√¢micas ao longo do tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_processed_lstm = df_sales_processed.copy()\n",
    "df_sales_processed_lstm.reset_index(inplace=True, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales_processed_lstm[\"time_idx\"] = (\n",
    "    df_sales_processed_lstm[\"date\"] - df_sales_processed_lstm[\"date\"].min()\n",
    ").dt.days\n",
    "df_sales_processed_lstm.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo os dados em conjuntos de treinamento, valida√ß√£o e teste\n",
    "training_df, validation_df, test_df = expanding_window_split(\n",
    "    df_sales_processed_lstm, 1, validation=True\n",
    ")\n",
    "\n",
    "# Criando e configurando o modelo LSTM, juntamente com o treinador e os dataloaders\n",
    "model, trainer, train_dataloader, val_dataloader, test_dataloader = modelagem_lstm(\n",
    "    training_df, validation_df, test_df, max_epochs=20\n",
    ")\n",
    "\n",
    "# Treinando o modelo LSTM\n",
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")\n",
    "\n",
    "# Obtendo as previs√µes do modelo LSTM para o conjunto de teste\n",
    "test_df_previsto = previsao_lstm(trainer, test_dataloader, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extrair previs√µes do melhor checkpoint do modelo\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_model = RecurrentNetwork.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizar as previs√µes do nosso modelo\n",
    "# com base na documenta√ß√£o do pytorch-forecasting, a sa√≠da de predict √© uma tupla de previs√£o com os campos prediction, x, index, decoder_lengths, y\n",
    "# https://pytorch-forecasting.readthedocs.io/en/stable/api/pytorch_forecasting.models.base_model.BaseModel.html#pytorch_forecasting.models.base_model.BaseModel.predict\n",
    "raw_predictions, x, _, _, _ = best_model.predict(test_dataloader, mode=\"raw\", return_x=True)\n",
    "\n",
    "for idx in range(2):  # plotar 3 exemplos\n",
    "    best_model.plot_prediction(x, raw_predictions, idx=idx, add_loss_to_title=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the cross-validated weighted MAE and MAPE for a model\n",
    "wmae_lista = []\n",
    "wmape_lista = []\n",
    "cv = 3\n",
    "max_epochs = 20\n",
    "\n",
    "resultados_lstm = []\n",
    "\n",
    "nome_previsto = \"lstm_pred\"\n",
    "\n",
    "for i in range(cv):\n",
    "    training_df, validation_df, test_df = expanding_window_split(\n",
    "        df_sales_processed_lstm, i, validation=True\n",
    "    )\n",
    "    model, trainer, train_dataloader, val_dataloader, test_dataloader = modelagem_lstm(\n",
    "        training_df, validation_df, test_df, max_epochs=max_epochs\n",
    "    )\n",
    "\n",
    "    test_df_previsto = previsao_lstm(\n",
    "        trainer, model, train_dataloader, val_dataloader, test_dataloader, test_df\n",
    "    )\n",
    "\n",
    "    wmae, wmape = calcular_wmae_wmape(training_df, test_df_previsto, \"sales\", nome_previsto)\n",
    "\n",
    "    wmae_lista.append(wmae)\n",
    "    wmape_lista.append(wmape)\n",
    "\n",
    "# Armazena os resultados em uma lista\n",
    "resultados_lstm.append(\n",
    "    {\n",
    "        \"Modelo\": nome_previsto,\n",
    "        \"WMAE - M√©dia CV\": np.mean(wmae_lista),\n",
    "        \"WMAE - Desvio Padr√£o CV\": np.std(wmae_lista),\n",
    "        \"WMAPE - M√©dia CV\": np.mean(wmape_lista),\n",
    "        \"WMAPE - Desvio Padr√£o CV\": np.std(wmape_lista),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Criando DataFrame com os resultados de ambos os m√©todos\n",
    "df_resultados_lstm = pd.DataFrame(resultados_lstm)\n",
    "\n",
    "# Exibir os resultados formatados\n",
    "# df_resultados_geral = pd.concat([df_resultados_geral, df_resultados_lstm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O nosso modelo **LSTM** apresentou um melhor desempenho comparado ao m√©todo **Prophet**, demonstrando uma capacidade superior de capturar padr√µes complexos nos dados. Embora o **Prophet** tenha se sa√≠do melhor que os m√©todos **Na√Øve** e **sNa√Øve**, reduzindo significativamente os erros por conseguir modelar sazonalidades e tend√™ncias, o **LSTM** conseguiu superar esses resultados.  \n",
    "\n",
    "Isso pode ser atribu√≠do √† capacidade das redes neurais recorrentes de aprender **padr√µes n√£o lineares e depend√™ncias de longo prazo**, tornando-as mais eficazes em s√©ries temporais mais complexas.  \n",
    "\n",
    "Diante desse cen√°rio, o **LSTM** se torna a melhor op√ß√£o para seguirmos com o **ajuste fino**, buscando otimizar ainda mais seu desempenho. No entanto, seguimos explorando outras abordagens para garantir que estamos utilizando o modelo mais adequado ao nosso problema. Apesar do desempenho superior, ainda podemos testar mais um modelo chamado TFT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Fusion Transformer (TFT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O **Temporal Fusion Transformer (TFT)** √© um modelo de **deep learning** projetado para modelagem de s√©ries temporais, sendo capaz de lidar tanto com **s√©ries multivariadas** quanto com **s√©ries univariadas**. Sua principal vantagem est√° na combina√ß√£o de **aten√ß√£o multi-head** e **redes LSTM**, permitindo capturar **rela√ß√µes complexas entre vari√°veis** e aprender **padr√µes temporais de curto e longo prazo** com alta precis√£o.  \n",
    "\n",
    "Embora seja amplamente utilizado para **s√©ries temporais multivariadas**, o **TFT** tamb√©m se mostra eficiente em **s√©ries univariadas**, aproveitando sua estrutura para identificar **tend√™ncias, sazonalidades e mudan√ßas de padr√£o ao longo do tempo**, sem a necessidade de m√∫ltiplas vari√°veis auxiliares. Al√©m disso, sua capacidade de **quantificar a import√¢ncia das entradas** o torna altamente interpret√°vel, algo que nem sempre √© poss√≠vel com modelos de redes neurais tradicionais.  \n",
    "\n",
    "Neste projeto, utilizamos o **TFT** como uma abordagem avan√ßada para previs√£o de s√©ries temporais, explorando sua flexibilidade para capturar padr√µes **tanto em contextos univariados quanto multivariados**, garantindo previs√µes mais precisas e interpret√°veis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>sales</th>\n",
       "      <th>series_id</th>\n",
       "      <th>sales_detrend</th>\n",
       "      <th>anomaly</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-29</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>7240.65</td>\n",
       "      <td>CA_1_FOODS</td>\n",
       "      <td>1494.960186</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>6705.51</td>\n",
       "      <td>CA_1_FOODS</td>\n",
       "      <td>958.505114</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>4584.85</td>\n",
       "      <td>CA_1_FOODS</td>\n",
       "      <td>-1163.469957</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date store_id cat_id    sales   series_id  sales_detrend  anomaly  \\\n",
       "0 2011-01-29     CA_1  FOODS  7240.65  CA_1_FOODS    1494.960186    False   \n",
       "1 2011-01-30     CA_1  FOODS  6705.51  CA_1_FOODS     958.505114    False   \n",
       "2 2011-01-31     CA_1  FOODS  4584.85  CA_1_FOODS   -1163.469957    False   \n",
       "\n",
       "   time_idx  \n",
       "0         0  \n",
       "1         1  \n",
       "2         2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copia o dataframe df_sales_processed\n",
    "df_sales_processed_transformer = df_sales_processed.copy()\n",
    "\n",
    "# Reseta o √≠ndice do dataframe e cria a coluna \"t\n",
    "# ime_idx\" com a diferen√ßa em dias desde a data m√≠nima\n",
    "df_sales_processed_transformer.reset_index(inplace=True, drop=False)\n",
    "df_sales_processed_transformer[\"time_idx\"] = (\n",
    "    df_sales_processed_transformer[\"date\"] - df_sales_processed_transformer[\"date\"].min()\n",
    ").dt.days\n",
    "\n",
    "# Exibe as primeiras 3 linhas do dataframe\n",
    "df_sales_processed_transformer.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 1087.7k\n"
     ]
    }
   ],
   "source": [
    "# Configura√ß√£o do lookback (7 dias -> 168 horas)\n",
    "lookback = 168  # Ajuste se necess√°rio\n",
    "\n",
    "# Comprimento da janela de previs√£o\n",
    "janela_previsao = 28\n",
    "\n",
    "# Divis√£o dos dados utilizando expanding_window_split\n",
    "training_df, validation_df, test_df = expanding_window_split(\n",
    "    df_sales_processed_transformer, 0, validation=True\n",
    ")\n",
    "\n",
    "# Cria√ß√£o do conjunto de dados de treino\n",
    "dados_treino = TimeSeriesDataSet(\n",
    "    training_df,  # Dados j√° filtrados\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"sales\",\n",
    "    group_ids=[\"series_id\"],\n",
    "    min_encoder_length=lookback // 2,\n",
    "    max_encoder_length=lookback,\n",
    "    static_categoricals=[\"series_id\"],\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=janela_previsao,\n",
    "    time_varying_known_reals=[\"time_idx\"],\n",
    "    time_varying_unknown_reals=[\"sales\"],\n",
    ")\n",
    "\n",
    "# Cria√ß√£o do conjunto de dados de valida√ß√£o (garante a sequ√™ncia cont√≠nua)\n",
    "dados_valid = TimeSeriesDataSet.from_dataset(\n",
    "    dados_treino,\n",
    "    pd.concat([training_df, validation_df]).reset_index(drop=True),\n",
    "    predict=True,\n",
    "    stop_randomization=True,\n",
    ")\n",
    "\n",
    "# Cria√ß√£o dos DataLoaders\n",
    "dl_treino = dados_treino.to_dataloader(train=True, batch_size=32, num_workers=2, pin_memory=True)\n",
    "dl_valid = dados_valid.to_dataloader(train=False, batch_size=32, num_workers=2, pin_memory=True)\n",
    "\n",
    "# Callbacks\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\", min_delta=1e-4, patience=5, verbose=True, mode=\"min\"\n",
    ")\n",
    "lr_logger = LearningRateMonitor()\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Logger para o TensorBoard\n",
    "logger = TensorBoardLogger(\"../reports/lightning_logs\")\n",
    "\n",
    "# Configura√ß√£o do Trainer\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=3,\n",
    "    accelerator=\"gpu\",\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.1,\n",
    "    callbacks=[lr_logger, early_stop_callback, checkpoint_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "quantis = [0.1, 0.5, 0.9]\n",
    "\n",
    "# Cria√ß√£o do modelo utilizando o TemporalFusionTransformer\n",
    "modelo_tft = TemporalFusionTransformer.from_dataset(\n",
    "    dados_treino,\n",
    "    learning_rate=0.00020417379446695298,\n",
    "    hidden_size=128,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=128,\n",
    "    output_size=len(quantis),\n",
    "    loss=QuantileLoss(quantis),\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "print(f\"Number of parameters in network: {modelo_tft.size() / 1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O **Temporal Fusion Transformer (TFT)** permite otimizar o treinamento encontrando automaticamente uma **taxa de aprendizado inicial ideal** usando o **Tuner do PyTorch Lightning**. A fun√ß√£o **`lr_find()`** testa diferentes valores e sugere a melhor taxa para acelerar o aprendizado e evitar problemas como **converg√™ncia lenta ou overfitting**. No entanto, para o **TFT**, a taxa ideal costuma ser **ligeiramente menor do que a sugerida**, pois o modelo √© sens√≠vel a varia√ß√µes. Ajustes finos s√£o recomendados para garantir um treinamento eficiente e de alto desempenho. üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Finding best initial lr:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 90/100 [00:06<00:00, 13.93it/s]\n",
      "LR finder stopped early after 90 steps due to diverging loss.\n",
      "Learning rate set to 0.00023988329190194915\n",
      "Restoring states from the checkpoint path at d:\\Estudo_Pessoal\\Portifolio\\ciencia_de_dados\\ts_forecast_dl_tft_dailysales\\notebooks\\.lr_find_e65b8e9b-8d72-4ac8-9087-9e85b6fe6f41.ckpt\n",
      "Restored all states from the checkpoint at d:\\Estudo_Pessoal\\Portifolio\\ciencia_de_dados\\ts_forecast_dl_tft_dailysales\\notebooks\\.lr_find_e65b8e9b-8d72-4ac8-9087-9e85b6fe6f41.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 0.00023988329190194915\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encontra a taxa de aprendizagem ideal\n",
    "res = pl.tuner.Tuner(trainer).lr_find(\n",
    "    modelo_tft,\n",
    "    train_dataloaders=dl_treino,\n",
    "    val_dataloaders=dl_valid,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(modelo_tft, train_dataloaders=dl_treino, val_dataloaders=dl_valid)\n",
    "\n",
    "# Carregar o melhor modelo salvo pelo checkpoint\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_model = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolha um √≠ndice v√°lido para visualizar uma amostra espec√≠fica\n",
    "idx = 0\n",
    "\n",
    "# Gera previs√µes com base no conjunto de valida√ß√£o\n",
    "raw_predictions, x, _, _, _ = best_model.predict(dl_valid, mode=\"raw\", return_x=True)\n",
    "\n",
    "# Faz o plot usando o m√©todo interno do modelo\n",
    "fig = best_model.plot_prediction(x, raw_predictions, idx=idx, add_loss_to_title=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def previsao_tft(training_df, validation_df, test_df, i, max_epochs=6):\n",
    "    \"\"\"\n",
    "    Treina o modelo TFT e faz previs√µes para um conjunto de teste.\n",
    "\n",
    "    Par√¢metros:\n",
    "        - training_df (DataFrame): Dados de treino.\n",
    "        - validation_df (DataFrame): Dados de valida√ß√£o.\n",
    "        - test_df (DataFrame): Dados de teste.\n",
    "        - i (int): √çndice da rodada de valida√ß√£o cruzada.\n",
    "        - max_epochs (int): N√∫mero m√°ximo de √©pocas de treinamento.\n",
    "\n",
    "    Retorna:\n",
    "        - test_df com as previs√µes adicionadas.\n",
    "    \"\"\"\n",
    "    val_idx = validation_df[\"time_idx\"].min()\n",
    "    test_idx = test_df[\"time_idx\"].min()\n",
    "\n",
    "    quantis = [0.1, 0.5, 0.9]\n",
    "\n",
    "    dados_treino = TimeSeriesDataSet(\n",
    "        training_df,\n",
    "        time_idx=\"time_idx\",\n",
    "        target=\"sales\",\n",
    "        group_ids=[\"series_id\"],\n",
    "        min_encoder_length=168 // 2,\n",
    "        max_encoder_length=168,\n",
    "        static_categoricals=[\"series_id\"],\n",
    "        min_prediction_length=1,\n",
    "        max_prediction_length=28,\n",
    "        time_varying_known_reals=[\"time_idx\"],\n",
    "        time_varying_unknown_reals=[\"sales\"],\n",
    "    )\n",
    "\n",
    "    validation_data = TimeSeriesDataSet.from_dataset(\n",
    "        dados_treino,\n",
    "        pd.concat([training_df, validation_df]).reset_index(drop=True),\n",
    "        min_prediction_idx=val_idx,\n",
    "        predict=True,\n",
    "        stop_randomization=True,\n",
    "    )\n",
    "\n",
    "    test_data = TimeSeriesDataSet.from_dataset(\n",
    "        dados_treino,\n",
    "        pd.concat([training_df, validation_df, test_df]).reset_index(drop=True),\n",
    "        min_prediction_idx=test_idx,\n",
    "        predict=True,\n",
    "        stop_randomization=True,\n",
    "    )\n",
    "\n",
    "    # Criando DataLoaders\n",
    "    dl_treino = dados_treino.to_dataloader(\n",
    "        train=True, batch_size=32, num_workers=2, pin_memory=True\n",
    "    )\n",
    "    dl_valid = validation_data.to_dataloader(\n",
    "        train=False, batch_size=32, num_workers=2, pin_memory=True\n",
    "    )\n",
    "    dl_teste = test_data.to_dataloader(\n",
    "        train=False, batch_size=32, num_workers=2, pin_memory=True\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=max_epochs,\n",
    "        accelerator=\"gpu\",\n",
    "        gradient_clip_val=0.1,\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\"),\n",
    "            ModelCheckpoint(monitor=\"val_loss\", mode=\"min\", save_top_k=1),\n",
    "        ],\n",
    "        logger=TensorBoardLogger(\"../reports/lightning_logs\", name=f\"tft_cv_fold_{i}\"),\n",
    "    )\n",
    "\n",
    "    modelo_tft = TemporalFusionTransformer.from_dataset(\n",
    "        dados_treino,\n",
    "        learning_rate=0.00023,\n",
    "        hidden_size=128,\n",
    "        dropout=0.1,\n",
    "        loss=QuantileLoss(quantis),\n",
    "    )\n",
    "\n",
    "    trainer.fit(\n",
    "        modelo_tft,\n",
    "        train_dataloaders=dl_treino,\n",
    "        val_dataloaders=dl_valid,\n",
    "    )\n",
    "    # Carregar o melhor modelo salvo durante o treinamento\n",
    "    best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "    best_model = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n",
    "\n",
    "    # Fazer previs√µes com o modelo treinado\n",
    "    predictions, _, index, _, _ = best_model.predict(dl_teste, return_index=True)\n",
    "\n",
    "    # Criar DataFrame com previs√µes\n",
    "    time_idx_start = index.loc[0, \"time_idx\"]\n",
    "    time_idx_end = time_idx_start + len(predictions[0])\n",
    "\n",
    "    predictions_df_wide = pd.DataFrame(\n",
    "        predictions.cpu().numpy(), columns=range(time_idx_start, time_idx_end)\n",
    "    )\n",
    "    predictions_df_wide[\"series_id\"] = index[\"series_id\"]\n",
    "    predictions_df = predictions_df_wide.melt(id_vars=[\"series_id\"])\n",
    "    predictions_df.rename(columns={\"variable\": \"time_idx\", \"value\": \"tft_pred\"}, inplace=True)\n",
    "\n",
    "    # Fazer merge com test_df\n",
    "    test_df_previsto = test_df.merge(predictions_df, on=[\"series_id\", \"time_idx\"], how=\"left\")\n",
    "\n",
    "    return test_df_previsto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Criar diret√≥rio para salvar o modelo final\n",
    "model_dir = \"../models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 330    | train\n",
      "3  | prescalers                         | ModuleDict                      | 48     | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 3.6 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 6.5 K  | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.1 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 66.3 K | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 66.3 K | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 66.3 K | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 66.3 K | train\n",
      "11 | lstm_encoder                       | LSTM                            | 132 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 132 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 33.0 K | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 256    | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 82.7 K | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 41.2 K | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 33.3 K | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 66.3 K | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 33.3 K | train\n",
      "20 | output_layer                       | Linear                          | 387    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "833 K     Trainable params\n",
      "0         Non-trainable params\n",
      "833 K     Total params\n",
      "3.333     Total estimated model params size (MB)\n",
      "210       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1672/1672 [02:30<00:00, 11.10it/s, v_num=11, train_loss_step=167.0, val_loss=286.0, train_loss_epoch=165.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 330    | train\n",
      "3  | prescalers                         | ModuleDict                      | 48     | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 3.6 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 6.5 K  | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.1 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 66.3 K | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 66.3 K | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 66.3 K | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 66.3 K | train\n",
      "11 | lstm_encoder                       | LSTM                            | 132 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 132 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 33.0 K | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 256    | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 82.7 K | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 41.2 K | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 33.3 K | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 66.3 K | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 33.3 K | train\n",
      "20 | output_layer                       | Linear                          | 387    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "833 K     Trainable params\n",
      "0         Non-trainable params\n",
      "833 K     Total params\n",
      "3.333     Total estimated model params size (MB)\n",
      "210       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1620/1620 [02:25<00:00, 11.10it/s, v_num=3, train_loss_step=188.0, val_loss=331.0, train_loss_epoch=172.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 330    | train\n",
      "3  | prescalers                         | ModuleDict                      | 48     | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 3.6 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 6.5 K  | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.1 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 66.3 K | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 66.3 K | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 66.3 K | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 66.3 K | train\n",
      "11 | lstm_encoder                       | LSTM                            | 132 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 132 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 33.0 K | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 256    | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 82.7 K | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 41.2 K | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 33.3 K | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 66.3 K | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 33.3 K | train\n",
      "20 | output_layer                       | Linear                          | 387    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "833 K     Trainable params\n",
      "0         Non-trainable params\n",
      "833 K     Total params\n",
      "3.333     Total estimated model params size (MB)\n",
      "210       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1567/1567 [02:23<00:00, 10.89it/s, v_num=2, train_loss_step=156.0, val_loss=370.0, train_loss_epoch=157.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo final salvo em: ../models/tft_pred_final_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Lista de m√©todos de previs√£o e seus respectivos nomes de coluna no DataFrame\n",
    "metodos_previsao = [\n",
    "    (previsao_tft, \"tft_pred\"),\n",
    "]\n",
    "\n",
    "cv = 3\n",
    "max_epochs = 20\n",
    "resultados_tft = []\n",
    "\n",
    "for metodo, nome_previsto in metodos_previsao:\n",
    "    wmae_lista = []\n",
    "    wmape_lista = []\n",
    "\n",
    "    # Inicializa o modelo uma √∫nica vez antes do CV\n",
    "    modelo_tft_final = None\n",
    "\n",
    "    for i in range(cv):\n",
    "        training_df, validation_df, test_df = expanding_window_split(\n",
    "            df_sales_processed_transformer, i, validation=True\n",
    "        )\n",
    "\n",
    "        test_df_previsto, modelo_tft = metodo(training_df, validation_df, test_df, i, max_epochs)\n",
    "\n",
    "        # Armazena o modelo treinado na √∫ltima itera√ß√£o\n",
    "        modelo_tft_final = modelo_tft\n",
    "        wmae, wmape = calcular_wmae_wmape(training_df, test_df_previsto, \"sales\", nome_previsto)\n",
    "\n",
    "        wmae_lista.append(wmae)\n",
    "        wmape_lista.append(wmape)\n",
    "\n",
    "    # Salvar o modelo final completo (depois do CV)\n",
    "    if modelo_tft_final:\n",
    "        final_model_path = os.path.join(model_dir, f\"{nome_previsto}_final_model.pth\")\n",
    "        torch.save(modelo_tft_final.state_dict(), final_model_path)\n",
    "        print(f\"Modelo final salvo em: {final_model_path}\")\n",
    "\n",
    "    # Armazena os resultados em uma lista\n",
    "    resultados_tft.append(\n",
    "        {\n",
    "            \"Modelo\": nome_previsto,\n",
    "            \"WMAE - M√©dia CV\": np.mean(wmae_lista),\n",
    "            \"WMAE - Desvio Padr√£o CV\": np.std(wmae_lista),\n",
    "            \"WMAPE - M√©dia CV\": np.mean(wmape_lista),\n",
    "            \"WMAPE - Desvio Padr√£o CV\": np.std(wmape_lista),\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Criando DataFrame com os resultados de ambos os m√©todos\n",
    "df_resultados_tft = pd.DataFrame(resultados_tft)\n",
    "\n",
    "# Exibir os resultados formatados\n",
    "# df_resultados_geral = pd.concat([df_resultados_geral, df_resultados_tft])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>WMAE - M√©dia CV</th>\n",
       "      <th>WMAE - Desvio Padr√£o CV</th>\n",
       "      <th>WMAPE - M√©dia CV</th>\n",
       "      <th>WMAPE - Desvio Padr√£o CV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tft_pred</td>\n",
       "      <td>543.051025</td>\n",
       "      <td>3.419763</td>\n",
       "      <td>0.098488</td>\n",
       "      <td>0.007961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Modelo  WMAE - M√©dia CV  WMAE - Desvio Padr√£o CV  WMAPE - M√©dia CV  \\\n",
       "0  tft_pred       543.051025                 3.419763          0.098488   \n",
       "\n",
       "   WMAPE - Desvio Padr√£o CV  \n",
       "0                  0.007961  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resultados_tft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados_geral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O nosso modelo **TFT (Temporal Fusion Transformer)** apresentou um desempenho ainda melhor em compara√ß√£o com o **LSTM**, mostrando uma capacidade superior de capturar padr√µes sazonais e tend√™ncias de forma mais eficiente. Embora o **LSTM** tenha superado o **Prophet**, reduzindo significativamente os erros ao aprender padr√µes n√£o lineares e depend√™ncias de longo prazo, o **TFT** conseguiu ir al√©m, combinando a flexibilidade das redes neurais com interpretabilidade aprimorada.  \n",
    "\n",
    "Isso se deve ao fato de que o **TFT** utiliza mecanismos avan√ßados, como **aten√ß√£o multi-head** e **redes LSTM**, permitindo modelar s√©ries temporais tanto **univariadas quanto multivariadas**, al√©m de atribuir pesos √†s vari√°veis mais relevantes para a previs√£o. Essa abordagem melhora a qualidade das previs√µes, tornando o modelo mais robusto e adapt√°vel a diferentes cen√°rios.  \n",
    "\n",
    "Diante desse resultado, o **TFT** se torna nossa melhor op√ß√£o para avan√ßarmos no projeto. Agora, seguimos para a pr√≥xima etapa: **a otimiza√ß√£o dos hiperpar√¢metros**, garantindo que o modelo alcance seu desempenho m√°ximo e forne√ßa previs√µes ainda mais precisas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
